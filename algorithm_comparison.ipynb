{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Comparing ID3 and CS4.5 Learning Algorithms implemented in Python\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Motivation\n",
    "\n",
    "In order to deeply understand the concepts involved as well as Compare these Algorithms, \n",
    "I will implement them each as a Class in base Python, train them on a sample Dataset and compare their learning rates,\n",
    "both graphically and with some key metrics (training time, accuracy, further metrics to be determined later).\n",
    "\n",
    "### Scope \n",
    "I will not define basic Concepts such Machine Learning and Decision Trees here.\n",
    "Finally, I consider the history of these Algorithms out of scope here.\n",
    "\n",
    "Even though this is not a purely or even predominantly mathematical Project I _will_ introduce the Algorithms briefly,\n",
    "both in order to improve my own understanding and to provide context.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "#### Entropy\n",
    "Having been very well defined elsewhere, I think about __Entropy__ in this specific context \n",
    "as the degree to which the varying outcomes of a probabilistic process are unbalanced.\n",
    "\n",
    "Simply put, a system has maximum entropy when all the outcomes are equally likely \n",
    "(think randomly picking a number from 1-100 where each numbers' probability of being chosen is 1%)\n",
    "and approaches zero entropy as an outcome becomes increasingly certain. \n",
    "\n",
    "> Formally: Given a random variable $X$, with possible outcomes $x_{i}$, each with probability $P_{X}(x_{i})$ \n",
    "> the entropy $H(X)$ is as follows\n",
    "> $$ H(x) = P_x(x_i) *  log_b P_x(x_i) $$\n",
    "> \n",
    ">source: [wikipedia](https://en.wikipedia.org/wiki/Entropy_(information_theory))\n",
    "> \n",
    ">the base $b$ is usually set at 2 for this specific case, representing a \"choice\" between 2 outcomes \n",
    "\n",
    "By this Token, the Entropy of picking a random Number between 1-100 can be calculated as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6438561897747395"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "\n",
    "probabilities = [.01] * 100\n",
    "entropy_example = -sum([i * log(.01, 2) for i in probabilities])\n",
    "entropy_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "graphically, let's look how entropy behaves in the most simple case from maximum to minimum:\n",
    "\n",
    "We start out with an equal coin toss with likelihood of 50 | 50 (maximum entropy) \n",
    "and end up with a perfectly unfair coin toss: 0 | 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "heads = .5\n",
    "tails = 1 - heads\n",
    "\n",
    "# we shift the likelihoods over from 0.5 - 0 and calculate entropy at each point\n",
    "# this time we use the entropy function from scipy\n",
    "# this could be vectorized with numpy, but at a list of this size...\n",
    "entropies = [entropy([(heads - i), tails], base=2) for i in [j * 0.005 for j in range(101)]]\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.stem(range(101),entropies, use_line_collection=True)\n",
    "plt.legend('likelihood of a coin toss - from equal to unfair, in steps of 1%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "as we can see, this looks like a classic logarithmic curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Information Gain\n",
    "Complementary to Entropy of a probabilistic process, Information Gain indicates the decrease of entropy that occurs \n",
    "due to knowledge of a specific feature of the process, or makes the outcome of the process more deterministic.\n",
    "\n",
    "> Formally _the expected information gain is the change in information entropy Î— \n",
    "> from a prior state to a state that takes some information as given:_\n",
    ">\n",
    "> $$ IG(T, a) = H(T) - H(T|a) $$\n",
    ">\n",
    "> where $H(T)$ describes the entropy of a system and $H(T|a)$ describes the entropy given and attribute $a$ \n",
    ">\n",
    "> source : [wikipedia](https://en.wikipedia.org/wiki/Information_gain_in_decision_trees)\n",
    "\n",
    "Informally, my heuristic for information gain is how much a new observation causes models and assumptions to be revised,\n",
    "the more surprising a new value, the more a model needs to be revised \n",
    "and therefore the more information is gained.\n",
    "\n",
    "More importantly concerning decision trees, information gain can be constructed in terms of \n",
    "the effect on entropy of splitting groups along a feature and look at the (posterior, conditional) entropy in the resulting groups \n",
    "compared to the prior entropy.\n",
    "If you're familiar with Bayes' Theorem, this should bring up some memories (fond or otherwise).\n",
    "\n",
    "> Formally that means we define the conditional entropy of a training set $ T $ given a feature $ a $ - $ H(T|a) $\n",
    "> as:\n",
    ">\n",
    "> $$ \\sum_{v \\in vals(a)} \\frac{|S_a(v)|}{|T|} \\cdot H(S_a(v))  $$\n",
    ">\n",
    "> here $S_a(v)$ denotes the subset of the training set $T$ for which the feature $a$ is applicable\n",
    "\n",
    "Ultimately, we calculate the entropy in all resulting subsets, multiply them by the relative sizes of the subsets \n",
    "and sum them up. \n",
    "So if we split Training group exactly in half on a feature, we calculate the entropy of subgroup a * .5 \n",
    "and the entropy of subgroup b * .5 and the sum would be our resulting entropy.\n",
    "\n",
    "To show a more tangible example:\n",
    "\n",
    "Assuming we have a group of 100 people and know only their height and their gender.\n",
    "Now we want to find the best \"cutoff\" height to split the group into male/female. We to this by:\n",
    "* picking a cutoff height, let's say 170cm and splitting the group in two\n",
    "* calculate conditional entropy in the group above / below given a height of more or less than 170 cm, respectively\n",
    "* multiply the conditional entropies by the group sizes (e.g. 35/100 and 65/100) and sum them up\n",
    "* calculate the difference between the original entropy of the whole set and the sums (the information gain)\n",
    "* record the information gain and shift the cutoff to the next possible value\n",
    "\n",
    "In Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height_centimeters</th>\n",
       "      <th>gender_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height_centimeters  gender_male\n",
       "0               171.0          1.0\n",
       "1               170.0          1.0\n",
       "2               174.0          1.0\n",
       "3               189.0          1.0\n",
       "4               174.0          1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# create normal distributions for M/F along height - wiki\n",
    "# label 1/0 \n",
    "# loop over all possible cutoffs\n",
    "# bar chart\n",
    "\n",
    "# we initialize a random seed, in order to get a consistent random ratio of men/women in our fictional group\n",
    "random.seed(42)\n",
    "males_ratio = round(random.random() * 100)\n",
    "\n",
    "mean_male = 177.8\n",
    "stdev_male = 10.16\n",
    "mean_female = 165.1\n",
    "stdev_female = 8.89\n",
    "\n",
    "distribution_male = np.random.normal(mean_male, stdev_male, size=males_ratio)\n",
    "distribution_female = np.random.normal(mean_female, stdev_female, size=(100-males_ratio))\n",
    "distribution_male = np.floor(distribution_male)\n",
    "distribution_female = np.floor(distribution_female)\n",
    "\n",
    "m_array = np.dstack((distribution_male, np.ones_like(distribution_male)))\n",
    "f_array = np.dstack((distribution_female, np.zeros_like(distribution_female)))\n",
    "all_array = np.hstack((m_array, f_array))\n",
    "\n",
    "all_array[0]\n",
    "df = pd.DataFrame(all_array[0], columns=['height_centimeters', 'gender_male'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutoff >= 149.0 - gain: 0.014869191307417151\n",
      "cutoff >= 151.0 - gain: 0.04541779172226801\n",
      "cutoff >= 152.0 - gain: 0.07712121756102308\n",
      "cutoff >= 155.0 - gain: 0.11007998351201898\n",
      "cutoff >= 156.0 - gain: 0.0870425465259469\n",
      "cutoff >= 157.0 - gain: 0.10262182058894065\n",
      "cutoff >= 158.0 - gain: 0.1187364456556631\n",
      "cutoff >= 159.0 - gain: 0.1353757420668632\n",
      "cutoff >= 160.0 - gain: 0.14174542988848549\n",
      "cutoff >= 161.0 - gain: 0.13593507434825236\n",
      "cutoff >= 162.0 - gain: 0.14927507071071344\n",
      "cutoff >= 163.0 - gain: 0.14776700660178355\n",
      "cutoff >= 164.0 - gain: 0.15357923940464846\n",
      "cutoff >= 165.0 - gain: 0.14025276664045105\n",
      "cutoff >= 166.0 - gain: 0.17506184616895915\n",
      "cutoff >= 167.0 - gain: 0.179816874084473\n",
      "cutoff >= 168.0 - gain: 0.1919277719550797\n",
      "cutoff >= 169.0 - gain: 0.25600779515213046\n",
      "cutoff >= 170.0 - gain: 0.24186070224371903\n",
      "cutoff >= 171.0 - gain: 0.21697123337576008\n",
      "cutoff >= 172.0 - gain: 0.2496486615457849\n",
      "cutoff >= 173.0 - gain: 0.21475074172430364\n",
      "cutoff >= 174.0 - gain: 0.18305786109114064\n",
      "cutoff >= 175.0 - gain: 0.20330000271068294\n",
      "cutoff >= 176.0 - gain: 0.15475036793804775\n",
      "cutoff >= 177.0 - gain: 0.22268318925549224\n",
      "cutoff >= 178.0 - gain: 0.21278200707502348\n",
      "cutoff >= 179.0 - gain: 0.20307315431786432\n",
      "cutoff >= 181.0 - gain: 0.18420251751254457\n",
      "cutoff >= 182.0 - gain: 0.16601577662925027\n",
      "cutoff >= 183.0 - gain: 0.14846362606524555\n",
      "cutoff >= 184.0 - gain: 0.13150204577412206\n",
      "cutoff >= 186.0 - gain: 0.12323022204526657\n",
      "cutoff >= 188.0 - gain: 0.11509155498672097\n",
      "cutoff >= 189.0 - gain: 0.09143227279179378\n",
      "cutoff >= 190.0 - gain: 0.06882765424629045\n",
      "cutoff >= 191.0 - gain: 0.047185803518158154\n",
      "cutoff >= 192.0 - gain: 0.040171646371737424\n",
      "cutoff >= 193.0 - gain: 0.03325276098381058\n",
      "cutoff >= 194.0 - gain: 0.026426546447525845\n",
      "cutoff >= 196.0 - gain: 0.019690508766571413\n",
      "cutoff >= 197.0 - gain: 0.01304225498168321\n",
      "cutoff >= 201.0 - gain: 0.006479487700858488\n"
     ]
    }
   ],
   "source": [
    "from information_gain import information_gain\n",
    "\n",
    "\n",
    "original = df['gender_male'].values\n",
    "\n",
    "# we use arange, because it is computationally cheaper than SORT \n",
    "# + also does not include the last element (which would leave one split part empty)\n",
    "for i in np.arange(df['height_centimeters'].min(), df['height_centimeters'].max()):\n",
    "    part_1 = df[df['height_centimeters'] > i]['gender_male'].values\n",
    "    part_2 = df[df['height_centimeters'] <= i]['gender_male'].values\n",
    "    print(f'cutoff >= {i} - gain: {information_gain(original, part_1, part_2)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149., 150., 151., 152., 153., 154., 155., 156., 157., 158., 159.,\n",
       "       160., 161., 162., 163., 164., 165., 166., 167., 168., 169., 170.,\n",
       "       171., 172., 173., 174., 175., 176., 177., 178., 179., 180., 181.,\n",
       "       182., 183., 184., 185., 186., 187., 188., 189., 190., 191., 192.,\n",
       "       193., 194., 195., 196., 197., 198., 199., 200., 201., 202., 203.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(df['height_centimeters'].min(), df['height_centimeters'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## The Iterative Dichotomiser 3 (ID3) Algorithm\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
